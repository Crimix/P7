\chapter{Worker}\label{workerLabel}
When the queue server receives a request to analyse a user's filter bubble, it
starts by creating a new instance of the \textc{Worker} class. The worker
acts as the central class when retrieving and analysing users' tweets.
Whenever a user is to be analysed, a new \textc{Worker} is created for that
task. As such, each task in the queue corresponds to a single worker.\nl

In \autoref{sec:workerImpl}, we start by describing how the worker acts
and present the process in which a worker retrieves and analyses tweets.
In \autoref{sec:rateLimit}, we discuss how the worker handles Twitter's
imposed rate limits, which were described in \autoref{cha:twitterAPI}.

\section{Implementation}\label{sec:workerImpl}
The worker starts by requesting a \textc{User} object for the relevant user.
Then, it retrieves a list of up to 3200 most recent tweets created by the user.
The next step for the worker is to retrieve the list of users that the user is
following, and retrieve and analyse their tweets. The retrieval and analysis of
tweets are done in parallel by splitting them into tasks. To retrieve and
analyse tweets, it uses the functions
\textc{GetTweetsFromUserAndAnalyse} and \textc{GetTweetsFromFriendsAndAnalyse}
to receive and analyse tweets from the user and the users it follows
respectively. These methods are found in the class called
\textc{TweetRetriever}.\nl

After analysing all the tweets necessary for determining a user's filter bubble,
the worker sends the result to the Database \ac{API}, which then stores the
resulting value in the database. During this, the Database \ac{API} also
notifies the front-end that a result is ready to be presented.

\subsection{Multithreading}\label{sec:taskSplit}
To speed up the retrieval of tweets, the process is split into a predefined
number of tasks that are run in parallel. This split is made such that each
account, the user is following, corresponds to a task. This approach is also
used when the worker analyses the tweets, such that each task can work on a
smaller subset of the problem. Here, the splitting is done such that each task
gets an equal amount of tweets. The analysis of tweets is also split into a
predefined number of tasks, but this amount may be increased by 1 if the
tweets can not be split among the tasks equally.

\subsection{Tweet retriever} \label{sub:tweetretriever}
There are two versions of the tweet retrieval process. The first version
is a legacy version that retrieves tweets and returns them as one list, such
that they can be saved in files locally or to be analysed at a later point.
The new implementation retrieves and analyses each Twitter account on their own
thread to save time, as described in \autoref{sec:taskSplit}. The code from the
legacy version is moved to the helper function \textc{GetTweetsFromUserHelper},
which both of the versions wrap around. To make this work, the helper method,
among others, receives the \textc{retrieveMethod} as a parameter. Since this
parameter is of the type \textc{Func<List<Tweet>>}, the helper method can take
any method as a parameter if it returns a list of tweets. This can be
seen on the three methods in the three code examples \autoref{legacyUserTweet}
and \autoref{NewUserTweet} where the calls on \textbf{line 3}, in the two
wrapper methods, give the last parameter as a lambda expression, which takes no
input as seen by \textc{()=>}.\\

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = Legacy method call. , label = legacyUserTweet ] 
public List<Tweet> GetTweetsFromUser(User user, AuthObj auth)
{	
    return GetTweetsFromUserHelper(user, auth, (() => TweetThreadMethod(user, auth)));
}
\end{lstlisting}
\end{minipage}

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = Current method call to speed up execution. , label
= NewUserTweet ] 
public void GetTweetsFromUserAndAnalyse(User user, AuthObj auth, Func<User, bool> checkDB, Func<List<Tweet>, AnalysisResultObj> classifyMethod, Func<AnalysisResultObj, User, bool> postToDB)
{
    GetTweetsFromUserHelper(user, auth, (() => TweetThreadMethod(user, auth, checkDB, classifyMethod, postToDB)));
}
\end{lstlisting}
\end{minipage}

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = The \textc{GetTweetsFromUserHelper} method., label
= UserTweetHelper]
private List<Tweet> GetTweetsFromUserHelper(User user, AuthObj auth, Func<List<Tweet>> retrieveMethod)
{
    List<Tweet> tweetList = new List<Tweet>();
    Task<List<Tweet>> task = new Task<List<Tweet>>(() => retrieveMethod());
    task.Start();
    task.Wait();
    tweetList.AddRange(task.Result);

    return tweetList;
}
\end{lstlisting}
\end{minipage}

The helper \autoref{UserTweetHelper}, was made to reuse code because the only
change would be the method to be called in the task on \textbf{line 4}.\\

\subsubsection{Retrieve method}
As mentioned in \autoref{sub:tweetretriever}, the \textc{retrieveMethod}
parameter can be replaced with any method that returns a list of tweets. Both
versions send the method \textc{TweetThreadMethod}, shown in
\autoref{tweetthreadmethod}. \\

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = The \textc{TweetThreadMethod} method., label =
tweetthreadmethod]
private List<Tweet> TweetThreadMethod(User user, AuthObj auth, Func<User, bool> checkDB = null, Func<List<Tweet>, AnalysisResultObj> classifyMethod = null, Func<AnalysisResultObj, User, bool> postToDB = null)
{
    bool alreadyExist = false;
    AnalysisResultObj tempResult = new AnalysisResultObj();
    List<Tweet> temp = new List<Tweet>();
    if (checkDB != null)
    {
        alreadyExist = checkDB(user);
		...
    }

    if (!alreadyExist)
    {
        temp = RetrieveTweets(user, auth);
		...	
        if (classifyMethod != null && postToDB != null)
        {
            tempResult = classifyMethod(temp); 
            postToDB(tempResult, user); 
            temp = new List<Tweet>();
        }
    }

    return temp;
}
\end{lstlisting}

\end{minipage}
The difference is that this method has a bunch of optional parameters. The
legacy version only passes a user and an authorisation object, while the new
version also passes the methods \textc{checkDB}, \textc{classifyMethod} and
\textc{postToDB}.
\textc{checkDB} is used to check if the user is already in the database. If it
is, it skips the tweet retrieval and analysis of the particular user.\\

\subsection{Parameter Methods}
The three methods mentioned in \autoref{sub:tweetretriever} -
\textc{checkDB}, \textc{classifyMethod} \\and \textc{postToDB} are defined in
the \textc{Worker} class under the names of \\\textc{CheckIfResultExistOnDB},
\textc{ClassifyTweet} and \textc{PostResultToDB} respectively. Here,
\textc{CheckIfResultExistOnDB} and \textc{PostResultToDB} also have a version
that links the followee being analysed to the user. The methods are defined
in \textc{Worker}, rather than \textc{TweetRetriever}, because they are
different for each worker, since the \\\textc{userRecordId} is different for
each request. Such a thing cannot be defined in the singleton class without the
need to pass the ID to each method. This way, it is still the worker's methods
that are used in a context where they have access to what is defined in the
worker.

\section{Rate Limits}\label{sec:rateLimit}
As described in \autoref{cha:req}, our system is required to adhere to Twitter's
rules regarding rate limits. This means that we can only make a limited number of
requests per 15-minute interval. As such, we need to monitor how many requests
we use and how many we have left. Whenever we run out of requests, we must
be able to put the retrieval of tweets on hold until we can make more requests.
In order to handle this, we have a number of methods in the \textc{LimitHelper}
class, which monitors how many requests we have left. This is done by sending a
request to the Twitter \ac{API} endpoint: \nl

\say{https://api.twitter.com/1.1/application/rate\_limit\_status.json} \nl

It should be noted that these requests come from a different pool of requests
than those to receive tweets. As such, these requests do not limit our tweet
retrieval. These requests are only made once for each worker, which then stores
how many requests it have and when the next batch of requests are available.
Whenever we run out of requests, we put the threads to sleep and wait for the
next batch of requests.











