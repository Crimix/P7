\section*{Week 37}
\subsection*{What Happend This Week}
This week we researched the topic  ``\fb'' and different methods for gathering a
vast amount of user data to identify a filter bubble. We decided to check some
social media sites as a source for user data, Facebook, Twitter and Reddit were
researched. We also investigated how to put user data into manageable
categories. During our Web Intelligence course, we learned about web crawlers,
see section \ref{subsec:crawler}, it is the method used by search engines to
collect data and will be examined.

We also planned our workflow this semester, we are going to use some elements
from SCRUM to manage what has to be done and who works on the tasks. We set up
our GIT repositories for code and report, and split some responsebilities out
between our members, like supervisor contact, repository and report.

\subsection*{Evaluation}
We have found a vast amount of user information, which we reckon could be used
to identify a \fb and split the workload out between members. We are slowly
starting to gain the knowlegde we need for the project. We decided to write our
report in Latex using Eclipse as editor and GIT for versions control, half the
group have done this before and for now, it is causing minor inconvenience for
two group members adjusting to this.

\subsection*{Next Week}
During next week we would like to have a draft for the different researched
parts, from this week, ready for the report. Klaus also sent some links with
usefull information, this should also be read and notes on it. Moreover, we also
want to make a written description of the problem we would like to solve this
semester.


%This week we have researched different social hubs, mainly Facebook and Twitter
% and some articles about how to place posts into categories on a topic; if
% people are for or against it. Description of web crawlers and explored some
% our possibilities for using it this semester. We have setup the work process
% for the semester, talked about the tools and methods we will be using to
% structure the project. 

%Mail: Couple of thoughts:
%Crawl social networks to get an idea of the expanse of the userâ€™s filterbubble,
%by analysing the influences from contacts and pages they follow. This could
% also include an analysis of their likes and shares/retweets. In addition to this, we
%could compare with preexisting knowledge of news sources/sites.
%Given a website sift for keywords and look for sites where there is a
%concentration of these these words, this can be repeated a number of times,
% with the first website as the root.

%Ideas on how to start:
%Facebook has a lot of data available, along with an reasonable? API.
%Research webcrawlers