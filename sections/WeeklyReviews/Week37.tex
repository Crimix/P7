\section*{Week 37}
\subsection*{What Happend This Week}
To start with the project we researched upon our topic ``\fb'' and different
methods for gathering a vast amount of user data to identify a filter bubble. We
decided to check social media sites as a source for user data; we thought about
Facebook, Twitter and Reddit. We also investigated how to use the user data we
could potentially gather and what we would want and do with it. During our Web
Intelligence course, we learned about web crawlers, see section
\ref{subsec:crawler}, it is the method used by search engines to collect data.

We planned our workflow this semester, we are going to use some elements from
SCRUM to manage what has and have to be done and who works on the tasks. We set
up GIT repositories for code and report and split some responsibilities out
between our members, such as supervisor contact, repository and report.

\subsection*{Reflection}
We have found that social media sites were a suitable choice to gather a vast
amount of user information, which we reckon can be used to identify a \fb. We
are still in the initiating phase of the project so much can change. We decided
to write our report in Latex, using Eclipse as editor and GIT for versions control.
This is the style half the group have been doing, and it is causing minor
inconvenience for two group members adjusting to this. During this week we might
have used a little too much time discussing work preferences, it would
propably be better to list and discuss the advantages and disadvantages of the
choices.

\subsection*{Next Week}
During the next week, we would like to have a draft ready for the different
researched parts, from this week, ready for the report. Our supervisor sent some
links with useful information, these should be examined and noted upon depending
on usage. Moreover, we also want to define a description of the problem we try
to solve this semester.

%This week we have researched different social hubs, mainly Facebook and Twitter
% and some articles about how to place posts into categories on a topic; if
% people are for or against it. Description of web crawlers and explored some
% our possibilities for using it this semester. We have setup the work process
% for the semester, talked about the tools and methods we will be using to
% structure the project. 

%Mail: Couple of thoughts:
%Crawl social networks to get an idea of the expanse of the userâ€™s filterbubble,
%by analysing the influences from contacts and pages they follow. This could
% also include an analysis of their likes and shares/retweets. In addition to this, we
%could compare with preexisting knowledge of news sources/sites.
%Given a website sift for keywords and look for sites where there is a
%concentration of these these words, this can be repeated a number of times,
% with the first website as the root.

%Ideas on how to start:
%Facebook has a lot of data available, along with an reasonable? API.
%Research webcrawlers