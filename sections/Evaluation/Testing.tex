\chapter{Testing}\label{cha:testing}
In order to determine the quality of the developed software solution, we have
performed a number of tests. These tests aim to assure the quality of the
determined results, and to ensure that the software is operating as expected.\nl

The tests were performed on a PC running Windows 10, and having a i5-7200U
3.1GHz processor, 256GB SSD, 8GB DDR4 RAM, and a 100/100mbps internet
connection.

\section{Speed Tests}\label{speedtestlavel}
The purposes of these tests are to document the speed of both the
classification models, discussed in \autoref{sec:BoW} and
\autoref{sec:NBImp}. The first test is to test the effiency of multi threading
the Bag-Of-Words model, while the second test is used to compare speed of the
two models.

\subsection{Bag-Of-Words Speed Test}\label{test:multithread}
The purpose of this test is to document the reason behind implementing a
multithreaded version of the classification method, which was described in
\autoref{subs:multithread}. 
The result of the running both the multi threaded bag of words algorithm and the
single threaded version on the same input. The result can be seen in
\autoref{speedTestResSingleThread} and \autoref{speedTestResMultiThread}.

\begin{table}[H]\centering
\begin{tabular}{|l|l|}
\hline
3060	&	Tweets pr batch 	\\\hline
500		&	Batches				\\\hline
17394	&	milliseconds		\\\hline
34.7	&	ms/batch 			\\\hline
\end{tabular}
\caption{Results from the single threaded speed test}
\label{speedTestResSingleThread}
\end{table}

\begin{table}[H]\centering
\begin{tabular}{|l|l|}
\hline
3060	&	Tweets pr batch 	\\\hline
500		&	Batches				\\\hline
9928 	&	milliseconds		\\\hline
19.8	&	ms/batch 			\\\hline
\end{tabular}
\caption{Results from the multi threaded speed test}
\label{speedTestResMultiThread}
\end{table}

The results of the test shows that the time it takes to analyse tweets has been
cut by 43\% by using the multi threaded version of algorithm 

\subsection{Speed Test Comparison}
In this test the classification speed of both the models will be compared. The
effeciency will be evaluated based on the time necessary to process a given
number of tweets. As such, each approach will process 819.200 tweets in batches
of 3200. These numbers have been chosen as we need a high enough amount to
accurately determine the average time necessary, and because each tweet
analysis will process a maximum of 3200 tweets, as this is the maximum amount
of tweets retrievable from a person.\nl

A subset of the results from the speed test can be seen in \autoref{table:stest}
together with the average tweets per second in \autoref{AvgTweetsPs}. The
full dataset can be found in \autoref{app:speedTest}.

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
Try Nr.:	&	BoW (ms)	&	BoW Tweet/s	&	Bayes (ms)	&	Bayes Tweet/s	\\\hline
1	&	55	&	58181	&	493	&	6490 \\\hline
2	&	22	&	145454	&	353	&	9065 \\\hline
3	&	30	&	106666	&	334	&	9580 \\\hline
4	&	23	&	139130	&	328	&	9756 \\\hline		
\end{tabular}
\caption{Subset of the results from the speed test}
\label{table:stest}
\end{table}

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|}\hline
					&	\textbf{BoW Tweet/s}	&	\textbf{Bayes Tweet/s}	\\\hline
\textbf{Average:}	&	124007				&	9410 					\\\hline	
\end{tabular}
\caption{Average number of tweets processed per second}
\label{AvgTweetsPs}
\end{table}

The results from this test show that the Bag-Of-Words model is the fastest
approach, being capable of processing around 120.000 tweets per second, while
the Naive Bayes model is capable of processing around 9500 tweets per second.
To put this into perspective, if a user were to follow 500 accounts, it would
result in a maximum of 16.000.000 tweets, which would take around 2 minutes to
process for the Bag-Of-Words model, and 26 minutes for the Naive Bayes model.
Considering that this amount of followed users is above average, we consider
this processing time as being acceptable for both of them.

\section{Accuracy Tests}
The purposes of these tests are to document the accuracy of both the
classification models. The first test is an accuracy of the Naive Bayes model,
while the second test is a comparison of the two models predictions.


\subsection{Naive Bayes Cross Validation}
The purpose of this test is to test the accuracy of the model by performing
cross validation on the training data. The idea is to split the training sets into two
parts, a training segment and a testing segment \citep[Ch. 7.5.2]{MIBook}. Due
to time constraints, the cross validation is done 4 times with 90 labeled
training tweets and 30 labeled testing tweets. These tweets have been shuffled
to not be in any particular order, and the sets are not balanced.\nl

Combining the results of the cross validation, the following confusion
matrix is constructed, see \autoref{tab:ConfMat}. The matrix shows the
hit rate of the the prediction compared to the labeled result
\citep{ConfusionMatrix}.

\begin{table}[H]
\centering
\begin{tabular}{l|l|l|l|}
\cline{2-4}
& Predicted Left & Predicted Neutral & Predicted Right \\ \hline 
\multicolumn{1}{|l|}{Labeled Left} & \textbf{25} & 9 & 3 \\ \hline
\multicolumn{1}{|l|}{Labeled Neutral} & 7 & \textbf{15} & 8  \\ \hline
\multicolumn{1}{|l|}{Labeled Right} & 6 & 7 & \textbf{40} \\ \hline
\end{tabular}
\caption{Confusion Matrix for the combined results of the validation tests}
\label{tab:ConfMat}
\end{table}

The accuracy of each of the validation can be seen in \autoref{tab:CrossVal}.
The table shows how many of the tweets were correctly predicted, as well as
the average accuracy. 

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Cross Validation & Test 1 & Test 2 & Test 3 & Test 4 & Average \\ \hline
Accuracy &  20/30 = 0.67 & 18/30 = 0.60 & 21/30 = 0.70 & 21/30 = 0.70 & 80/120 =
0.67 
\\ \hline
\end{tabular}
\caption{Accuracy for each of the cross validations}
\label{tab:CrossVal}
\end{table}

In addition it is also of interest to look at the precision, which is how often
the prediction class is the correct class. Calculating the precision helps
measure if the accuracy is scewered towards a specific class. Using
\autoref{tab:ConfMat} the average precision is calculated in \autoref{e:PL},
\autoref{e:PN} and \autoref{e:PR}.

\begin{equation}\label{e:PL}
Precision(Left) = \cfrac{25}{25+7+6} = 0.66
\end{equation}
\begin{equation}\label{e:PN}
Precision(Neutral) = \cfrac{15}{9+15+7} = 0.48
\end{equation}
\begin{equation}\label{e:PR}
Precision(Right) = \cfrac{40}{3+8+40} = 0.78
\end{equation}

Based on these tests it is possible to see that the model is very bad at
predicting tweets belonging to the \textit{neutral} class, while it is far
better at predicting tweets belonging to the \textit{right} class. The accuracy
and precision could be improved by training on a larger set, and insuring the
the the validation sets are balanced.

\subsection{Accuracy Test Comparison}
The purpose of this test is to compare the accuracy of the two different
approaches to classification discussed in \autoref{sec:BoW} and
\autoref{sec:NBImp}. The accuracy will be determined by comparing the results
from the classification with a set of manually pre-classified twitter users.
The chosen users consists of politicians, activists, and a set of average
twitter users. A subset of the results from the accuracy test can be seen in
\autoref{speedTestReslabel} together with the percentage success in
\autoref{AccPercent}. The full dataset can be found in
\autoref{app:AccuracyTest}.\nl

A subset of the dataset from the accuracy test can be seen below in
\autoref{speedTestReslabel}. Each test shows one pre-classified user, and the
results determined from the bag-of-words model and the Naive Bayes model.\fix{
The result consist of a value between -10 and 10, where a low value implies
left-leaing views, and a high value implies right-leaning views. The
bag-of-words (BoW) model also has a conclusion, which is dependent on the
percentage of tweets considered political, and the size of the determined value.
For the BoW model, a user with less than 1\% political tweets, or a determined
value between 1 and -1, is automatically considered as neutral.}{Should
probably be described in implementation and referenced} The percentage accuracy
of each model can be seen in \autoref{AccPercent}.
The columns represent the following, from left to right:\nl

\begin{itemize}
  \item The percentage of tweets the BoW model
consider political in nature.
\item Numeric result from BoW model.
\item Conclusion from BoW model.
\item Numeric result from the Bayes model.
\item Conclusion from the Bayes model.
\item Actual political leaning of the analyzed user.
\end{itemize}

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Pol\%:}	&	\textbf{Alg:}	&	\textbf{Alg Conc:}							&	\textbf{Bayes:}	&
\textbf{Bayes Conc:}
& \textbf{Actual:}
\\\hline 0.64	&	-2.42	&	Left/Neutral (Pol\% too low)		&	5.82	&	Right		&	Left	\\\hline
1.82	&	-0.865	&	Right								&	3.16	&	Right		&	Right	\\\hline
8.25	&	-3.219	&	Left								&	2.55	&	Right		&	Left	\\\hline
1.39	&	0.5		&	Right/Neutral (Result is 0 +/- 1)	&	3.51	&	Right		&	Right	\\\hline
\end{tabular}
\caption{Results from the speed test}
\label{speedTestReslabel}
\end{table}



\begin{table}[H]\centering
\begin{tabular}{|l|l|}\hline
\textbf{Accuracy BoW}	&	\textbf{Accuracy Bayes}	\\\hline
96.67\%					&	43.33\%					\\\hline	
\end{tabular}
\caption{Average number of tweets processed per second}
\label{AccPercent}
\end{table}

The results from this test show that the Bag-Of-Words model is capable of
accurately classifying 96\% of the test users. The Naive Bayes models has
problems with classifying real users, as it has classified every user as being
biased towards the right, this has provided it with an accuracy of 43.33\%. As
such we consider the Bag-Of-Words model to be the most succesful until the Naive
Bayes model has received more training.


and the naive bayes approach classifying 46\%. Though the


\section{Tweet Retrieval Test}
The purpose of this test is to document the limitations of retrieving tweets
through the Twitter API. This is important as the speed at which we can retrieve
tweets sets an upper limit to how fast we can present an output to the user.
The speed will be determined by calling the twitter API from the worker class,
and documenting the amount of tweets we can recieve over a set amount of time.
The Worker class and tweet retrieval is discussed in \autoref{workerLabel}.

\subsection*{Results}
A subset of the dataset from the tweet retrieval test can be seen below in
\autoref{tweetRetReslabel}, and the full dataset can be found in
\autoref{app:tweetRet}.
Each test shows the retrieval of tweets from 5 different users, and the result is the total tweets retrieval per second in
total from all five concurrent threads. The average tweets per second can be
seen in \autoref{RetNumberAvg}. 

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Nr.:}	&	\textbf{Time (ms):}	&	\textbf{Tweets/s:} \\\hline
1	&	8603	&	332.6\\\hline
2	&	9385	&	304.8\\\hline
3	&	8229	&	347.7\\\hline
4	&	9454	&	302.6\\\hline
\end{tabular}
\caption{Subset of the results from the tweet retrieval test}
\label{tweetRetReslabel}
\end{table}

\begin{table}[H]\centering
\begin{tabular}{|l|}\hline
\textbf{Average Tweets/s}	\\\hline
310.0 Tweets \\\hline
\end{tabular}
\caption{Average number of tweets retrieved per second}
\label{RetNumberAvg}
\end{table}

The results from this test show that we can retrieve a maximum of 310 tweets per
second. Considering the speed of processing these tweets, as shown in
\autoref{speedtestlavel}, this represents the greatest bottleneck for the
system.
 




\section{Stress Testing}
The purpose of this test is to ensure the system's ability to queue requests
from multiple users. This is important, as the system should be scalable such
that it can handle an undefined amount of users at a time. The test consists of
calling the code in \autoref{stressTestCode} 25 times. This code sends a request
to our Queue API at the address \textc{localhost:62020}.\nl

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = Code initiating the stress test, label = stressTestCode] 
bool DatabaseSendDataRequest(params string[] parameters){
...
	HttpWebRequest request = (HttpWebRequest)WebRequest.Create("localhost:62020/API/AnalyzeTwitterAccount");
...
}
\end{lstlisting}
\end{minipage}

The results of this test was that the system was indeed capable of handling the
requests. This shows that the system is scalable in that it can handle an
undefined amount of requests from different people at a time.


\section{Functional Testing}
In order to assure that the system is working as indended, we have performed a
number of functional tests, in which we supply an input to the system, and
monitor that each individual part of the system performs as expected. In the
first step, we enter the input into the frontend. This can be seen in
\autoref{testRequest}.\nl 

\figx[0.5]{testRequest}{Initial screen where the user inputs their Twitter name}

After inputting the twitter name, we make a request to the database for any data
relating to that name. If the data is present, we go directly to the result in
\autoref{}. If the data is not present, we prepare to perform the tweet
retrieval and analysis. As such, we request that the user authenticate using
Twitter's site. This can be seen in \autoref{twitterAuthTab}.\nl

\figx{twitterAuthTab}{Twitter's website for authorizing access for an
application}

After clicking the ``Godkend Applikation'' button, the user is given a unique
password. This can be seen in \autoref{twitterPin}.\nl

\figx{twitterPin}{Unique password supplied by Twitter}

Back in our application, we request that the user enter this password
together with an email address of their choosing. This can be seen in
\autoref{twitterAuth}.\nl

\figx{twitterAuth}{Requesting a password and email address from the user}

After the user inputs the password, we show the screen in \autoref{testDialog}.
Then the application makes a request to Twitter's API, and recieves the user's
\textc{access\_token} and \textc{access\_token\_secret}. This information is
then used to request tweets from all the accounts that the specified user is
following. These tweets are then analyzed in relation to their sentiment
(positivity/negativity), and their political leaning (left/right). The output
log from the program can be seen in \autoref{tweetlogAnal}. \nl

\figx[0.75]{testDialog}{Dialog presented when a user has submitted a request}

\begin{minipage}[H]{\linewidth}
\begin{lstlisting}[caption = Log from tweet retrieval and analysis, label = tweetlogAnal] 
12-12-2017 10:37:37 | Debug~ Task entered queue with ID ODotTWJtc3dBQUFBQUE...
12-12-2017 10:37:37 | Debug~ Task started ODotTWJtc3dBQUFBQUE...
12-12-2017 10:38:10 | Debug~ Donald J. Trump                25073877             2874       
12-12-2017 10:38:10 | Debug~ Spliting 2874 tweets
12-12-2017 10:38:10 | Debug~ Combining tweets
12-12-2017 10:38:10 | Debug~ Result 5,21428571428571
12-12-2017 10:38:13 | Debug~ Following 45 users
...
12-12-2017 10:52:09 | Debug~ Done task with id ODotTWJtc3dBQUFBQUE...!!!
\end{lstlisting}
\end{minipage}

From the log in \autoref{tweetlogAnal} we can see that the entire tweet
retrieval and analysis process took 15 minutes. The reason for the delay is that
each user has a limited amount of tweets per 15 minute period. As such, the
threads responsible for retrieving tweets were put to sleep while waiting for
more requests.\nl

When the system backend finishes processing the tweets, it returns the request
from the frontend to tell it that a result is ready. The frontend then sends a
mail to the user's specified email account. This email can be seen in
\autoref{email}, where the user must click the ``See Result" button.\nl

\figx{email}{Email sent to the user when processing is finished}

After clicking the button, the user will be redirected to a custom page on our
website, which will present the results in various graphs. This can be seen in
\autoref{result2}.\nl

\figx{result2}{Column diagram showing the distribution of political leaning}

Based on the results of this test, we can confirm that every part of the system
is capable of interacting correctly with eachother.





