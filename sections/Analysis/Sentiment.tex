\chapter{Data Analysis}\label{cha:DA}
Using similar ideas as \cited{pennacchiotti2011machine}, we want to analyse
Twitter data to find a user's political views. Instead of using a general
machine learning approach as they do, we instead try to determine it like we
would with sentiment, using similar models to \cited{sarlan2014twitter} and
\cited{go2009twitter}.\nl

Sentiment analysis attempts to determine user's opinions regarding specific
topics, such as movies or products. This technique has become especially useful
for social media, as people increasingly discuss and post their opinions online
\citep[Overview 2]{Sentiment}. Additionally, since sentiment analysis can be
used to determine users' opinions on products, it should be possible to apply
this analysis to politicians, legislature, political events and other political
talking points. Sentiment analysis is done by gathering text post and comments,
and extracting features providing clues to the opinion. The features can then
be used with a classification model to predict the sentiment.\nl

In \autoref{sec:FeatEx} we examine how to transform text into useful
\textit{features}, and which options are available to increase the quality of
those \textit{features}. In \autoref{sec:Class} we will look at how the
\textit{features} can be used in models to make predictions. In
\autoref{sec:mediaAnalysis} we discuss how user's preference in news media can
help in indicating their political leanings. Finally in \autoref{sec:DAConc} we
will conclude on the analysis.

\section{Feature Extraction}\label{sec:FeatEx}
Feature extraction is a method used after the tokenization, to choose which
words best determine the sentiment. Much can be lost in the feature extractor,
as the opinions are more apparent in text than as a series of tokens. There are
several ways to express the sentiment in a text, such
as\citep[Overview.3-4]{Sentiment}:


\begin{itemize}
  \item Capitalization. 
  \item Lengthening.
  \item Punctuation.
  \item Stopwords.
  \item Negation.
\end{itemize}

For instance, there is a big difference between person one saying ``I love this
movie'' and person two saying ``I LOVE this movie!!!!''. In this example, both
the capitalisation of ``love'' and the exclamation mark helps to emphasise that
person two seems to have a stronger positive sentiment towards the movie.\nl

An example of lengthening as a difference in sentiment could be between
``huuuungry'', ``huuungry'' and ``hungry". The differences in sentiment between
the first two variations of ``hungry" are probably minimal, but there is an
apparent difference between those and the last version. To compress these
features one can look for tokens with more than two of the same letters repeated
and removing the repeated letters. This will make the loss of sentiment minimal
while limiting the variations of the same word.\nl

It is useful to remove stopwords, which are words that do not contain valuable
information. As they can appear in every type of sentence, they can make
classification more difficult, though it also mainly depends on the model,
see \autoref{subsub:Models}.\nl

Negation also needs to be considered, as the sentiment can be changed entirely
with a word ``not''. Because sentiment gets extracted from tokens, it is
difficult to judge how each token relate to others when seen individually. A way
to handle negation is to prefix tokens with a tag such as ``NEG\_'' after a word
like ``not'' and ``aren't''.\nl

See \autoref{tab:feature} for an example of how a feature extraction can look.

\begin{table}[H]
\centering
\begin{tabular}{|p{6cm}|p{8cm}|}
\hline
Text & Features \\ \hline
I LOVED the movie but I am sooooo hungry! & 
``I'' ``LOVED'' ``movie'' ``I'' ``soo'' ``hungry'' ``!''
\\ \hline 
I don't like this song, why do they keep playing it? &
``I'' ``dont'' ``like'' ``NEG\_song'' ``NEG\_why'' ``NEG\_keep'' ``NEG\_playing''
``?'' \\ \hline
\end{tabular}
\caption{An example of transforming text into features.}
\label{tab:feature}
\end{table}

There are a couple of other methods that can affect how much sentiment is
retained in the text, such as stemming and using n-grams.

\subsection{Stemming}\label{subsec:Stem}
Stemming is a method used with feature extraction, to collapse a word into its
base, for instance ``finding'' can be stemmed to ``find''. Stemming is both
useful and destructive. It allows for a reduction in the number of terms by
collapsing them. It is also destructive as sentiment clues can get erased. The
meaning of a word can often have ties to the ending of the word, such as
``captivating'' and ``captive''. By using the Porter Stemmer Algorithm, both
words will collapse to ``captiv'' which removes what differentiate them. There
are other Stemmer algorithms, but each provides similar problems. Stemming can
be useful as it can reduce the vocabulary, instead of remembering both
``captivating'' and ``captive'', it now only needs to remember ``captiv''. This
can be useful for small datasets where each token is important, as it can reduce
the vocabulary size and sharpen the result \citep[Ch 3.b]{Sentiment}.

\subsection{N-Grams}
N-grams are a sequence of 'n' items and determines how much context is stored
from a piece of text. An example of the three first n-grams, seen in
table \autoref{tab:ngram}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
Text & ``I love horror movies'' \\ \hline
Unigrams (1) &
``I'' ``love'' ``horror'' ``movies''
\\ \hline 
Bigram (2) &
``I love'' ``love horror'' ``horror movies''
\\ \hline
Trigram (3) &
``I love horror'' ``love horror movies''
\\ \hline
\end{tabular}
\caption{An example of different N-Grams}
\label{tab:ngram}
\end{table}

The idea is that as bigger n-grams are used, more context gets stored in the
token. It becomes less likely to encounter a given token, which should
improve accuracy if there is a large training sample. With smaller training
samples it becomes necessary to use unigrams as there are not enough
token occurrences to justify using bigger n-grams.

\subsection{Feature Vectors}\label{sub:FeatureVector}
A feature vector is used to denote which features are present in a piece of
text. The vector gets created by mapping each feature to a unique integer, this
is done while training the model and is called a Bag-Of-Words (not to be
confused with the Bag-Of-Words classification model, described in
\autoref{subsub:Models}). With this Tokens-To-Integers the feature vector can
now be created as a series, often array, of 1's or 0's, which denotes whether
the given feature is present in the vector. The bigger the Bag-Of-Words is, the
larger every feature vector is. For example if ``\textit{love}'' is mapped to
\textbf{3} and ``\textit{movie}'' is mapped to \textbf{205}, then a feature
vector for ``\textit{I love this movie}'' could be: [0,0,0,1,0,\ldots,0,1,0].


\section{Classification}\label{sec:Class}
The final part of a sentiment analysis is the classification task. This task
consists of predicting the sentiment based on the features extracted earlier.
The accuracy of the predictions is based on the labelled data provided as
training data, as well as the model used.

\subsection{Training}\label{subsec:Train}
The training data is an important part of every model. There are three
different training methods, each suitable for a different task.

\begin{itemize}
  \item \textbf{Supervised learning} is when the training data is paired as an
  input-output pair, for instance: ``This is a great movie'' can be paired with
  ``positive''. This pairing allows the model to verify its prediction whether
  it guesses correct or not \citep[Ch. 7.0]{MIBook}. This method is useful as it
  provides an easy way to validate the accuracy of the model. The main problem
  is that most data is not labelled, which means that it has to be labelled for
  it to be useful.
  \item \textbf{Reinforcement learning} is similar to supervised learning with
  the key difference being that the model is only given a ``reward'' when it
  performs the best action. This type of learning method is useful when training
  a robotic agent \citep{Reinforcement}.
  \item \textbf{Unsupervised learning} is different as the training data no
  longer includes a result, and as such, it can no longer evaluate the accuracy
  of the prediction. Instead, it allows for clustering data and aims to minimize
  prediction errors \citep[Ch. 11.1]{MIBook}.
\end{itemize}

The most used model for sentiment analysis, is the supervised learning approach,
as it is the most useful for classification tasks.

\subsection{Models}\label{subsub:Models}
There are several different models used for sentiment analysis. Different models
provide varying levels of accuracy, as seen in \autoref{sentiment}, which shows
several different models on the same IMDB dataset, with three different outputs.
While we do not go in depth about all the models that are available, we will
describe the models that are of immediate interest to us. A cursory description
of different models can be found in the citation \citep{Classification}.

\figx[1.0]{sentiment}{Accuracy of different sentiment analysis models on the
IMDB dataset \citep{Classification}.}

Our main focus will be on the Bag-Of-Words and Naive Bayes models, as both
are straightforward methods of determining sentiment, which should help with
providing proof of concept.

\subsubsection{Bag-Of-Words}
The Bag-Of-Words model determines the sentiment of a text by counting the
occurrences of words with either a negative or positive attitude. Some models
simply count the occurrences of positive or negative words, but int other models
words can have different sentiment scores where one word may be perceived as
conveying a more intense sentiment than others. Each word and its corresponding
sentiment score gets stored in a sentiment lexicon, these lexicons can be
created by or found freely online \citep{BagOfWords}. An example of words and
their sentimental value can be seen in \autoref{tab:bowwords}.

\begin{table}[H]\centering
\begin{tabular}{|l|l|}\hline
\textbf{Word:} & \textbf{Sentiment:} \\\hline
LOVE	&	15	\\\hline
Love	&	10	\\\hline
Like	&	5	\\\hline
HATE	&	-15	\\\hline
Hate	&	-10	\\\hline
Dislike	&	-5	\\\hline
\end{tabular}
\caption{Sentimental words and their corresponding values}
\label{tab:bowwords}
\end{table}

\subsubsection{Naive Bayes} 
The Naive Bayes classifier uses Bayes' rule and the assumption of independence,
which simply assumes that the features are independent of each other
\citep[Proposition 6.5]{MIBook}, to determine the sentiment. Bayes' rule, see
\autoref{e:Bayes}, describes how prior knowledge can relate to and affect an
event \citep[P.229]{MIBook}. 

\begin{equation}\label{e:Bayes}
P(X|Y) = \cfrac{P(Y|X) \cdot P(X)}{P(Y)}
\end{equation}


It trains using supervised learning, where each text object gets labelled with a
class. The text features get extracted as tokens and, the probability of each
token belonging to each of the labels is then calculated, by counting how often
it occurs with each class; leading to a table such as \autoref{tab:NB}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Word & Positive & Negative & Total 	\\ \hline
this & 45 & 55 & 100				\\ \hline
movie & 115 & 85 & 200				\\ \hline
rule & 90 & 10 & 100				\\ \hline
suck & 5 & 95 & 100					\\ \hline
Total & 255 & 245 & 500				\\ \hline
\end{tabular}
\caption{A table where each token is classified with a label.}
\label{tab:NB}
\end{table}

To predict which class, \textit{C}, a given piece of text belongs to it needs to
be transformed into a feature vector, \textit{W}, where each feature gets
denoted as, $w_{i}$. By using \autoref{e:Score} we can predict the class
\citep[Ch.2.1]{Bayes}.
\begin{equation}\label{e:Score} score(W,C) = P(C) \cdot
\displaystyle\prod_{i=1}^{n}P(w_{i}|C)
\end{equation}

The idea is to calculate the probability of the feature vector belonging to each
of the classes. The class probabilities $P(C)$ are determined how frequently the
classes have been observed to occur, therefor:
\begin{center}
$P(C_{Pos}) = \cfrac{255}{500} = 0.51 $ and $P(C_{neg}) = \cfrac{245}{500} =
0.49 $
\end{center}
The probabilities of each of the features are likewise found by how often the
features occur. For instance, if we want to determine the class of ``this
movie rule'', with the probabilities from \autoref{tab:NB}, we get the
following feature vector [1,1,1,0]. We can then calculate the score of
the feature vector belonging to each of the classes:

\begin{equation}\label{e:Pos}
score(W, C_{Pos}) = \cfrac{255}{500} \cdot \cfrac{45}{100} \cdot
\cfrac{115}{200} \cdot \cfrac{90}{100} = 0.238
\end{equation}
\begin{equation}\label{e:Neg}
score(W, C_{Neg}) = \cfrac{245}{500} \cdot \cfrac{55}{100} \cdot \cfrac{85}{200}
\cdot \cfrac{10}{100} = 0.019
\end{equation}

Then by taking the highest score we the can predict the class the text belongs
to, in this case, it would be positive.

\section{Media Analysis}\label{sec:mediaAnalysis}
When retrieving tweets from Twitter we can also recieve some additional
information such as location, timestamps, and shared links. Among these, shared
links specifically can be used to determine a user's political leanings. This is
useful as news media sites often have an inherent political bias
\citep{allSides}. As such, if we can identify a link as coming from one of
these sites, we can conclude that the user sharing the link is more likely to be
of the same political leaning. In order to identify the bias of different news
media sites, one can make use of online resources such as \textc{AllSides.com},
which has community- and expert-driven classifications of different news
media \citep{allSidesBias}. Examples of news media and their rating can be seen
in \autoref{tab:newsmedia}.

\begin{table}[H]\centering
\begin{tabular}{|l|l|}\hline
\textbf{News Media:} & \textbf{Rating:}	\\\hline
CNN				&	Left		\\\hline
ABC News		&	Center-Left	\\\hline
Forbes			&	Neutral		\\\hline
Fox News		&	Center-Right\\\hline
Breitbart News	&	Right		\\\hline
\end{tabular}
\caption{News media and their political bias}
\label{tab:newsmedia}
\end{table}

\section{Data Analysis Conclusion}\label{sec:DAConc}
Based on our research into sentiment analysis, we can conclude that this
approach is well suited for classifying vast amounts of user data. It is
especially useful for analysing the sentiment around American politics as there
are only two main parties with opposing views, which means that not only are
there few classes, they should also be very distinct. By determining the
sentiment, it becomes possible to see if a user is inside a political bubble,
where the user only encounters the same sentiment. Based on the our analysis, we
have chosen to make use of two different approaches to determining a user's
filter bubble. The first is based on a Naive Bayes Network, and the second is
based on a Bag-of-Words model, which also makes use of the media analysis
described in \autoref{tab:newsmedia}.

Using this information about the problem area and the possible ways to identify
a filter bubble, \autoref{ch:problem} will construct a final problem statement,
which will be used to guide development of the software solution.

%https://www.cs.cornell.edu/home/llee/papers/sentiment.pdf